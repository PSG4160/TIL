![](https://velog.velcdn.com/images/gyu_p/post/f917d663-74f5-4602-9000-338a0450d371/image.png)

### 딥러닝 CNN 기본개념 및 동작원리

Convolutional Neural Networks (CNN)은 이미지 처리와 같은 다양한 딥러닝 작업에 주로 사용되는 인공 신경망 구조임. CNN은 데이터가 입력층으로 들어오면, 여러 단계의 처리를 거쳐 최종적으로 결과를 출력함. 이번 글에서는 CNN의 전체적인 흐름과 각 단계의 역할, 그리고 ReLU 활성화 함수에 대해 자세히 알아봄.

#### CNN의 전체 흐름
CNN의 전체적인 처리 흐름은 다음과 같음:
1. **입력층**: 이미지 데이터와 같은 입력이 주어짐.
2. **컨볼루션 층(Conv)**: 입력 데이터와 필터(가중치들의 집합체)를 사용해 컨볼루션 연산을 수행해 이미지의 특징을 추출함.
3. **ReLU 활성화 함수**: 컨볼루션 층에서 얻은 출력을 ReLU 함수를 통해 비선형성을 도입해 복잡한 패턴을 학습할 수 있도록 만듦.
4. **풀링 층(Pooling)**: 데이터의 크기를 줄이고, 모델의 복잡도를 낮춰 연산 속도를 높임. 대표적인 방식은 최대 풀링(Max Pooling)임.
5. **완전연결층(Fully Connected Layer)**: 추출된 특징을 기반으로 최종적으로 분류나 예측을 수행함.
6. **출력층**: 최종 결과가 출력됨.

이러한 흐름을 통해 CNN은 입력 데이터의 저수준(low-level) 특징부터 고수준(high-level) 특징까지 점점 더 복잡하고 추상적인 정보를 학습할 수 있게 됨. 아래에서는 각 단계의 역할을 자세히 살펴봄.

#### Conv (컨볼루션, Convolution)
컨볼루션 층에서는 입력 데이터와 필터(가중치들의 집합체)를 사용해 컨볼루션 연산을 수행함. 이 연산은 이미지의 지역적 특징을 추출하는 역할을 함. 예를 들어, 가장 기본적인 엣지(경계)나 특정 패턴을 감지하는 데 사용될 수 있음. 필터는 데이터의 다양한 특성을 학습하며, 여러 필터들이 함께 작동해 이미지에서 추출할 수 있는 유용한 정보를 많이 가져옴. 필터를 적용해 입력 데이터의 크기를 줄이면서 중요한 정보만 남기는 것이 컨볼루션의 목적임.

##### 예시
- **컨볼루션 연산 예시**: 아래와 같은 입력 데이터와 3x3 필터가 있다고 가정해봄.
  - 입력 데이터:
    ```
    [[1, 2, 1, 0],
     [0, 1, 3, 2],
     [2, 1, 0, 1],
     [1, 0, 1, 2]]
    ```
  - 필터:
    ```
    [[1, 0, -1],
     [1, 0, -1],
     [1, 0, -1]]
    ```
  - 이 필터를 입력 데이터에 적용하는 과정은 다음과 같음:
    1. 필터를 입력 데이터의 좌측 상단에 위치시킨 후, 각 위치의 값들을 곱한 후 모두 더함.
       - 예: `(1*1) + (2*0) + (1*-1) + (0*1) + (1*0) + (3*-1) + (2*1) + (1*0) + (0*-1) = 3`
    2. 다음 위치로 필터를 이동시키며 같은 방식으로 연산을 수행함.
    3. 이를 통해 각 위치에 대해 특징을 계산해 아래와 같은 특징 맵을 얻음:
    ```
    [[3, 1],
     [2, 0]]
    ```
  이 결과는 원래 이미지에서 수직적인 특징을 감지하는 데 유용하게 사용됨.

#### ReLU (Rectified Linear Unit)
ReLU는 입력 값을 0 이하일 때는 0으로, 0보다 큰 경우에는 그대로 반환하는 활성화 함수임. 수식으로 표현하면 **max(0, x)**임. 이 과정은 비선형성을 도입해 모델이 복잡한 패턴을 학습할 수 있도록 도움.

예를 들어, 이미지의 픽셀 값이 -10에서 10까지의 범위에 있을 때, ReLU를 적용하면 음수인 픽셀 값들은 모두 0이 되고 양수 값들은 그대로 유지됨. 이로 인해 계산이 간단해지고, 신경망이 활성화되지 않는 불필요한 신호를 제거해 학습 효율을 높임.

아래 그림처럼 ReLU 함수는 음수 부분에서는 값을 0으로 변환하고 양수 부분에서는 그대로 유지하는 단순하지만 매우 강력한 역할을 함.

![](https://velog.velcdn.com/images/gyu_p/post/62619e58-0fde-4c3c-86ce-34554782c4c5/image.png)


#### Pooling (풀링)
풀링 단계에서는 입력 정보의 크기를 줄여 데이터의 연산량을 감소시킴. 가장 흔히 사용되는 방식은 **최대 풀링(Max Pooling)**으로, 일정한 영역 내에서 가장 큰 값을 선택하는 방법임. 예를 들어 2x2 영역에서 가장 큰 값을 선택하면, 전체 데이터의 크기를 절반으로 줄일 수 있음. 이를 통해 모델의 연산 속도가 향상되며, 약간의 이동에도 큰 영향을 받지 않는(invariant) 특성을 가지게 됨.

##### 예시
- **Max Pooling 예시**: 예를 들어, 아래와 같은 2x2 영역에서 풀링을 수행한다고 가정해봄.
  - 입력: [[1, 3], [2, 4]]
  - Max Pooling 결과: 4
  이 과정은 정보의 중요한 부분만을 추출하고 나머지는 버리는 형태로, 계산 효율성을 극대화함.

#### CNN 전체 동작 과정 요약
입력 데이터(이미지)가 CNN의 입력층으로 들어오면, 첫 번째 컨볼루션 층에서 필터와의 연산을 통해 중요한 특징들을 추출함. 이 데이터를 ReLU 함수를 통해 비선형성을 추가하고, 이어서 풀링을 통해 데이터 크기를 줄임. 이러한 Conv -> ReLU -> Pooling 과정을 여러 번 반복한 후, 마지막에는 완전연결층(fully connected layer)을 통해 분류나 예측 작업을 수행함.

CNN의 이러한 계층적 구조 덕분에 입력 데이터의 저수준(low-level) 특징부터 고수준(high-level) 특징까지 점점 더 복잡하고 추상적인 정보를 학습할 수 있게 됨. 특히 ReLU와 풀링 과정은 데이터를 정제하고 연산 효율을 높여주는 중요한 역할을 하며, 모델의 성능을 크게 향상시킴.

#### CNN의 컨볼루션 층을 여러 개 쌓을 때의 변화
컨볼루션 층을 여러 개 쌓게 되면 모델이 학습하는 특징은 점점 더 복잡하고 추상적인 형태로 변화함. 첫 번째 컨볼루션 층에서는 주로 엣지나 텍스처 같은 저수준(low-level) 특징을 학습함. 이후 층이 깊어질수록 색상이나 형태, 구체적인 패턴 등 고수준(high-level) 특징을 학습하게 됨. 예를 들어, 초기 층에서는 선이나 점 같은 단순한 패턴을 감지하지만, 깊은 층으로 갈수록 사람의 얼굴이나 특정 사물과 같은 더 복잡한 패턴을 인식할 수 있게 됨. 이러한 계층적 특징 학습 덕분에 CNN은 복잡한 이미지 데이터를 효과적으로 분석하고 분류할 수 있음.

#### 결론
CNN은 이미지 처리에 매우 적합한 구조를 가지고 있으며, Conv, ReLU, Pooling과 같은 기본 단위들을 통해 데이터의 특징을 점진적으로 학습함. ReLU는 단순하지만 효율적으로 비선형성을 도입하고, 풀링은 데이터를 압축해 효율성을 높임. 이를 통해 CNN은 이미지나 영상 같은 시각적 데이터를 처리하는 데 강력한 성능을 발휘함.

