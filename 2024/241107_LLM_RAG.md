[블로그](https://velog.io/@gyu_p/LLM%EA%B3%BC-RAG%EC%97%90-%EB%8C%80%ED%95%9C-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90)
# 1. LLM(Large Language Model)이란 무엇인가?
## 1.1 LLM의 개념
**LLM(Large Language Model)**은 인간의 언어를 이해하고 생성하는 데 특화된 인공지능 모델입니다. 수십억에서 수조 개의 매개변수를 학습하여 복잡한 언어 패턴과 문맥을 파악하며, 다양한 자연어 처리(NLP) 작업에서 뛰어난 성능을 보입니다.

매개변수의 중요성: 매개변수의 수는 모델의 표현력과 일반화 능력에 직접적인 영향을 줍니다. 매개변수가 많을수록 더 복잡한 언어 패턴을 학습할 수 있지만, 계산 자원과 훈련 시간이 증가합니다.



## 1.2 LLM의 작동 원리
Self-Attention Mechanism: 입력 시퀀스 내에서 각 단어가 다른 모든 단어와의 관계를 학습합니다. 이는 문장의 의미를 더 정확하게 파악하는 데 도움이 됩니다.

예를 들어, "그는 은행에서 돈을 인출했다"에서 "은행"은 금융 기관을 의미하지만, "그는 강 옆의 은행에서 쉬고 있었다"에서는 "은행"이 나무를 의미합니다. Self-Attention 메커니즘은 이러한 문맥을 이해하여 적절한 의미를 추론합니다.

Positional Encoding : 트랜스포머는 순차적인 정보를 처리하지 않기 때문에, 단어의 위치 정보를 추가하기 위해 포지셔널 인코딩을 사용합니다. 이를 통해 단어의 순서를 인식하고 문맥을 이해합니다.

## 1.3 LLM의 훈련 방법
사전 훈련(Pre-training): 대규모의 비지도 학습 데이터(인터넷에서 수집한 텍스트 등)를 사용하여 모델을 사전 훈련합니다. 이 과정에서 언어의 일반적인 패턴과 구조를 학습합니다.

마스크드 언어 모델링(Masked Language Modeling): 일부 단어를 마스킹하고 이를 예측하도록 훈련합니다. `BERT` 모델이 이 방법을 사용합니다.
자동 회귀 언어 모델링(Autoregressive Language Modeling): 이전 단어들을 기반으로 다음 단어를 예측합니다. `GPT` 계열 모델이 이 방법을 사용합니다.
파인 튜닝(Fine-tuning): 사전 훈련된 모델을 특정 작업이나 도메인에 맞게 레이블된 데이터를 사용하여 미세 조정합니다. 이를 통해 모델이 특정 과업(번역, 요약, 질의응답 등)에 최적화됩니다.

## 1.4 LLM의 대표적인 모델들
### GPT 시리즈(OpenAI):

- GPT-2: 15억 개의 매개변수를 가진 모델로, 다양한 텍스트 생성 작업에서 뛰어난 성능을 보였습니다.
- GPT-3: 1750억 개의 매개변수를 가진 초대형 모델로, 코드 생성, 번역, 질의응답 등 광범위한 작업을 수행할 수 있습니다.
- GPT-4: GPT-3의 후속 모델로, 더욱 향상된 성능과 안전성을 제공합니다.

### BERT(Google):

- BERT: 양방향 문맥 이해를 위한 모델로, 마스크드 언어 모델링과 다음 문장 예측을 통해 훈련되었습니다.
- RoBERTa: BERT의 변형으로, 더 큰 데이터셋과 긴 훈련 시간으로 성능을 개선했습니다.

### T5(Google):

- T5(Text-to-Text Transfer Transformer): 모든 NLP 작업을 텍스트 입력에서 텍스트 출력으로 통합하여 처리합니다. 예를 들어, 번역, 요약, 질의응답 모두를 하나의 프레임워크에서 수행합니다.

## 1.5 LLM의 응용 분야

자연어 생성(NLG):

- 기사 작성: 자동으로 뉴스 기사나 블로그 포스트를 생성합니다.
- 스토리텔링: 창의적인 이야기나 소설을 작성합니다.

기계 번역:
- 다양한 언어로 된 텍스트를 정확하게 번역합니다.

질의응답(Q&A):

- 지식 베이스나 문서에서 정보를 추출하여 질문에 답변합니다.

요약(Summarization):

- 긴 문서나 기사의 핵심 내용을 요약합니다.

감성 분석(Sentiment Analysis):

- 소셜 미디어나 리뷰에서 감정이나 의견을 분석합니다.

## 1.6 LLM의 한계
계산 자원과 비용:

- 훈련 비용: 수십억 개의 매개변수를 가진 모델을 훈련하려면 막대한 계산 자원과 시간이 필요합니다.
- 에너지 소비: 환경적인 측면에서 대규모 모델의 에너지 소비는 중요한 문제입니다.

데이터 편향성(Bias):

- 편향된 데이터: 모델이 학습하는 데이터에 포함된 편향은 출력에도 영향을 미칩니다.
- 윤리적 문제: 인종, 성별, 문화적 편견 등이 모델의 응답에 나타날 수 있습니다.

추론 속도:

- 실시간 응답: 모델의 크기가 커질수록 추론 속도가 느려져 실시간 응답이 필요한 응용에 적용이 어려울 수 있습니다.

이해력과 창의성의 한계:

- 진정한 이해 부족: LLM은 통계적인 패턴을 학습한 것이지, 인간처럼 의미를 이해하는 것은 아닙니다.
- 논리적 추론의 한계: 복잡한 논리나 수학적 추론에서 한계를 보입니다.

# 2. RAG (Retrieval Augmented Generation)

## 개요

**RAG(Retrieval Augmented Generation)**는 대형 언어 모델(LLM)의 언어 생성 능력과 정보 검색 시스템의 정확성을 결합한 인공지능 기술입니다. LLM이 내재적으로 가지고 있는 지식에 더해, 외부 데이터 소스에서 관련 정보를 검색하여 응답의 **정확성**, **신뢰성**, **최신성**을 향상시킵니다.

---

## 2.1 RAG의 개념

- **Retrieval**: 외부 데이터베이스나 지식 베이스에서 사용자의 질문과 관련된 정보를 검색합니다.
- **Augmented Generation**: 검색된 정보를 LLM에 제공하여 더 정확하고 맥락에 맞는 응답을 생성합니다.

---

## 2.2 RAG의 작동 원리

1. **질문 처리**: 사용자의 입력 질문을 이해하고 전처리합니다.
2. **질문 임베딩**: 질문을 벡터 형태로 변환합니다.
3. **정보 검색**: 벡터화된 질문과 유사한 문서를 벡터 데이터베이스에서 검색합니다.
4. **응답 생성**: 검색된 문서를 기반으로 LLM이 최종 응답을 생성합니다.

---

## 2.3 구성 요소

###  질문 임베딩

- **Sentence Transformers**: 질문을 벡터로 변환하는 데 사용됩니다.
- **벡터화의 목적**: 의미적 유사성을 측정하기 위해 질문을 수치화합니다.

###  벡터 데이터베이스

- **기능**: 대용량의 임베딩된 문서를 저장하고, 유사성 검색을 빠르게 수행합니다.
- **예시**: FAISS, Annoy, Milvus 등.

###  정보 검색 모듈

- **역할**: 질문과 가장 유사한 문서를 선택합니다.
- **방법**: 코사인 유사도, 유클리드 거리 등을 사용한 벡터 유사성 계산.

###  언어 생성 모델(LLM)

- **역할**: 검색된 문서를 기반으로 자연스러운 언어로 응답을 생성합니다.
- **예시**: GPT-3, GPT-4, T5 등.

---

## 2.4 RAG의 유형

###  직접 생성(End-to-End Generation)

- **방식**: 검색과 생성을 하나의 모델 내에서 수행합니다.
- **특징**: 모델이 검색된 정보를 동적으로 활용하여 응답을 생성합니다.

###  분리된 생성(Separate Retrieval and Generation)

- **방식**: 검색과 생성을 별도의 모듈로 분리하여 수행합니다.
- **특징**: 모듈 간 교체나 업그레이드가 용이합니다.

---

## 2.5 RAG의 장점

- **정확성 향상**: 최신 정보와 사실에 기반한 응답 생성.
- **모델 크기 감소**: 외부 지식을 활용하므로 LLM의 크기를 줄일 수 있습니다.
- **도메인 적응성**: 특정 분야의 데이터로 검색 시스템을 구성하여 전문적인 응답 제공.

---

## 2.6 RAG의 활용 예시

###  고객 지원 챗봇

- **상황**: 제품 관련 문의에 대한 답변 제공.
- **동작**: FAQ나 매뉴얼에서 정보를 검색하여 정확한 답변 생성.

###  의료 정보 제공

- **상황**: 환자의 증상에 대한 의료 조언 제공.
- **동작**: 최신 의학 논문이나 진료 지침을 참고하여 응답 생성.

###  법률 상담

- **상황**: 법률 관련 질문에 대한 답변 제공.
- **동작**: 법률 조항이나 판례 데이터를 검색하여 정확한 정보 제공.

---

## 2.7 RAG 구현 시 고려사항

###  데이터 품질

- **중요성**: 검색되는 정보의 품질이 응답의 신뢰성에 직접적인 영향을 미칩니다.
- **조치**: 데이터 정제 및 업데이트를 주기적으로 수행.

###  모델 최적화

- **검색 속도**: 실시간 응답을 위해 벡터 검색의 최적화가 필요합니다.
- **응답 생성 시간**: LLM의 추론 속도를 개선하여 사용자 경험 향상.

###  윤리적 고려

- **프라이버시 보호**: 민감한 정보가 노출되지 않도록 데이터 관리 필요.
- **편향성 제거**: 공정하고 균형 잡힌 응답을 위해 데이터 편향성 검토.

---

LLM과 RAG의 기본적인 개념과 작동원리에 대해서 알아봤다. 
앞으로 공부와 실습을 병행하면서 시간이 빨리 지나갈 예정이다...
