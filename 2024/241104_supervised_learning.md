# 머신러닝 지도학습의 회귀 모델: 선형회귀, 다항회귀, 리지회귀, 라쏘회귀

---

## 1. 회귀 분석이란 무엇인가?
   - **정의**: 회귀 분석은 연속적인 값을 예측하는 데 사용되는 머신러닝 모델로, 특정 변수(독립 변수)에 따라 타겟 변수(종속 변수)를 예측합니다.
   - **예시**: 주택 가격 예측, 주식 가격 예측, 소비자의 지출 예측 등.

---

## 2. 선형회귀 (Linear Regression)
   - **정의**: 선형회귀는 독립 변수와 종속 변수 간의 선형적인 관계를 가정하는 회귀 모델입니다.
   - **수학적 표현**: $y = \beta_0 + \beta_1 x + \epsilon$
       - $y$: 종속 변수 (타겟 값)
       - $x$: 독립 변수 (입력 값)
       - $\beta_0, \beta_1$: 회귀 계수 (가중치)
       - $\epsilon$: 오차항 (오차값)
   - **학습 방법**: 주어진 데이터를 기반으로 손실 함수(주로 MSE)를 최소화하는 방향으로 최적의 $\beta$ 값을 찾습니다.
   - **활용**: 데이터가 선형적 관계를 가진 경우, 단순하고 빠르게 예측이 가능합니다.
   - **한계**: 데이터가 비선형 관계일 경우 모델 성능이 저하될 수 있습니다.

---

## 3. 다항회귀 (Polynomial Regression)
   - **정의**: 다항회귀는 비선형 관계를 모델링하기 위해 입력 변수 $x$를 다항식 형태로 확장하여 선형 회귀 모델에 적용하는 방법입니다.
   - **수학적 표현**: $y = \beta_0 + \beta_1 x + \beta_2 x^2 + ... + \beta_n x^n + \epsilon$
       - 다항식 차수가 높아질수록 더 복잡한 패턴을 학습할 수 있습니다.
   - **활용**: 데이터가 비선형 관계를 가진 경우, 더 높은 예측 성능을 낼 수 있습니다.
   - **주의점**: 과적합 위험이 증가할 수 있으며, 차수가 높아질수록 복잡도와 계산 비용이 증가합니다.

---

## 4. 리지 회귀 (Ridge Regression)
   - **정의**: 리지 회귀는 손실 함수에 규제 항을 추가하여 과적합을 방지하는 선형 회귀 모델입니다. L2 정규화를 통해 모델의 가중치(계수)가 너무 커지지 않도록 제약을 주며, 이로 인해 모델의 복잡도가 낮아져 일반화 성능이 개선됩니다.
   
   
 
   - **수학적 표현**: $\text{Loss} = MSE + \alpha \sum \beta_i^2$
   	- $\text{MSE}$: 평균 제곱 오차로, 예측값과 실제값 간의 오차를 나타냅니다.
    
    - $\alpha$: 규제 파라미터 (하이퍼파라미터로, 모델이 학습 중에 적용할 규제의 정도를 조절)
    
    - $\sum \beta_i^2$: 가중치 $\beta_i$의 제곱합을 더하여 큰 가중치가 발생하는 것을 억제합니다.
    
    - 이 식에서 $\alpha$가 클수록 규제가 강해지면서 가중치가 작아지며, 과적합이 줄어들지만 모델의 학습 능력도 약해질 수 있습니다.
    
   - **활용**: 데이터가 다중 공선성 문제를 가질 때 효과적이며, 모델의 일반화 성능을 높여줍니다.
   - **L2 정규화**:
	- L2 정규화는 모델의 가중치(계수) 값이 지나치게 커지지 않도록 제약을 가하는 방식입니다.
	- 리지 회귀에서 L2 정규화를 사용하면 가중치의 제곱합을 손실 함수에 추가하여 가중치가 클 때 패널티가 부과됩니다.
	- L2 정규화는 가중치를 0에 가깝게 만드는 경향이 있지만, 가중치 자체를 0으로 만들지는 않습니다(이 점이 L1 정규화와 다른 점입니다).
    
   - **L2 정규화 예시**
	가중치 크기를 억제하는 것이 왜 중요한지 간단한 예시로 살펴보겠습니다.

	- 예를 들어, 주택 가격 예측을 위해 가구 수, 방 개수, 평수 등 여러 변수를 이용한다고 가정해봅시다.

	- 특정 변수(예: 방 개수)의 가중치가 매우 크다면, 모델은 이 변수에 크게 의존하게 되어 다른 변수들의 영향력이 무시될 가능성이 큽니다.

	- L2 정규화는 이러한 큰 가중치를 억제하여 모든 변수들이 모델 학습에 골고루 기여할 수 있도록 돕습니다.

	- 비유로 설명: 마치 균형 잡힌 요리에서 특정 재료의 맛이 너무 강해지지 않도록 조절하는 것과 같습니다. 각 재료가 적절한 역할을 해 조화를 이루게 하는 것이 모델의 과적합을 방지하는데 중요한 역할을 합니다.
    
   - **한계**: 규제가 너무 강하면 모델의 성능이 저하될 수 있습니다.

---

## 5. 라쏘 회귀 (Lasso Regression)
   - **정의**: 라쏘 회귀는 리지 회귀와 유사하게 규제 항을 추가하지만, 절대값을 사용하여 가중치 $\beta_i$를 제한합니다.
   - **수학적 표현**: $\text{Loss} = MSE + \alpha \sum |\beta_i|$
       - 절대값을 통해 특정 가중치를 0으로 만들어 특성 선택을 가능하게 합니다.
   - **활용**: 불필요한 변수(특성)를 자동으로 제거하여 더 단순한 모델을 만들 수 있습니다.
   - **한계**: 중요한 변수가 무작위로 제거될 위험이 있어 성능이 저하될 수 있습니다.

---

## 6. 각 회귀 모델의 비교
   - **선형회귀**: 가장 기본적인 모델로, 선형 관계를 가진 데이터에 적합.
   - **다항회귀**: 비선형 데이터를 다루는 데 적합하나 과적합 위험 존재.
   - **리지 회귀**: 다중 공선성 문제 해결에 효과적이며, 규제를 통해 모델 복잡도를 조절.
   - **라쏘 회귀**: 특성 선택이 필요한 경우 유용하며, 간결한 모델을 생성할 수 있음.

---


